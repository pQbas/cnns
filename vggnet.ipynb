{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGNet\n",
    "\n",
    "<p align=\"center\"><img src=https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png>\n",
    "\n",
    "\\begin{equation*}\n",
    "\n",
    "\\underbrace{{CNN}^2 \\rightarrow MP}_\\textrm{Layer 1,2} \\rightarrow \n",
    "\\underbrace{{CNN}^2 \\rightarrow MP}_\\textrm{Layer 3,4} \\rightarrow \n",
    "\\underbrace{{CNN}^3 \\rightarrow MP}_\\textrm{Layer 5,6,7} \\rightarrow \n",
    "\\underbrace{{CNN}^3 \\rightarrow MP}_\\textrm{Layer 8,9,10} \\rightarrow \n",
    "\\underbrace{{CNN}^3 \\rightarrow MP}_\\textrm{Layer 11,12,13} \\rightarrow \n",
    "\\underbrace{ {(FC  \\rightarrow DO)}^2}_\\textrm{Layer 14,15} \\rightarrow \n",
    "\\underbrace{ Linear }_\\textrm{Layer 16} \\rightarrow softmax\n",
    "\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "<center>\n",
    "\n",
    "| Oper       | Datos                       | Activ. Func|  Notas |\n",
    "|:----------:|:---------------------------:|:----------:|:------:|\n",
    "| Conv1      | #k=64,  ks=3x3, s=1, p=1    | relu       |        |\n",
    "| Conv2      | #k=64,  ks=3x3, s=1, p=1    | relu       |        |\n",
    "| MaxPool    | ks=2x2, s=2                 |            |        |\n",
    "| Conv3      | #k=128, ks=3x3, s=1, p=1    | relu       |        |\n",
    "| Conv4      | #k=128, ks=3x3, s=1, p=1    | relu       |        |\n",
    "| MaxPool    | ks=2x2, s=1                 |            |        |\n",
    "| Conv5      | #k=256, ks=3x3, s=1, p=1    | relu       |        |\n",
    "| Conv6      | #k=256, ks=3x3, s=1, p=1    | relu       |        |\n",
    "| Conv7      | #k=256, ks=3x3, s=1, p=1    | relu       |        |\n",
    "| MaxPool    | ks=2x2, s=2                 |            |        |\n",
    "| Conv8      | #k=512, ks=3x3, s=1, p=1    | relu       |        |\n",
    "| Conv9      | #k=512, ks=3x3, s=1, p=1    | relu       |        |\n",
    "| Conv10     | #k=512, ks=3x3, s=1, p=1    | relu       |        |\n",
    "| MaxPool    | ks=2x2, s=2                 |            |        |\n",
    "| Conv11     | #k=512, ks=3x3, s=1, p=1    | relu       |        |\n",
    "| Conv12     | #k=512, ks=3x3, s=1, p=1    | relu       |        |\n",
    "| Conv13     | #k=512, ks=3x3, s=1, p=1    | relu       |        |\n",
    "| MaxPool    | ks=2x2, s=2                 |            |        |\n",
    "| FC1        | 4096                        | relu       |        |\n",
    "| Dropout    | p=0.5                       |            |        |\n",
    "| FC2        | 4096                        | relu       |        |\n",
    "| Dropout    | p=0.5                       |            |        |\n",
    "| FC3        | 1000                        | softmax    |        |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\percy\\anaconda3\\envs\\vision\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from utils import get_dataset, imshow, get_default_device, create_directory, save_model\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (18, 10)\n",
    "import torch.optim as optim\n",
    "from utils import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(conv, self).__init__()\n",
    "        self.filter_bank = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.filter_bank(x)\n",
    "        return x\n",
    "    \n",
    "class pooling(nn.Module):\n",
    "    def __init__(self, size, stride):\n",
    "        super(pooling, self).__init__()\n",
    "        self.pooling = torch.nn.MaxPool2d(kernel_size=size, stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pooling(x)\n",
    "        return x\n",
    "    \n",
    "class lrn(nn.Module):\n",
    "    def __init__(self, neighbors):\n",
    "        super(lrn, self).__init__()\n",
    "        self.lrn_ = nn.LocalResponseNorm(neighbors)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lrn_(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class linear(nn.Module):\n",
    "    def __init__(self, input, output):\n",
    "        super(linear, self).__init__()\n",
    "        self.linear_ = nn.Sequential(\n",
    "            nn.Linear(input, output),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "input shape: torch.Size([32, 3, 224, 224])\n",
      "output shape: torch.Size([32, 1000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class vggnet16(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(vggnet16, self).__init__()\n",
    "                \n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, 1, 1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, 1, 1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, 3, 1, 1)\n",
    "        self.conv7 = nn.Conv2d(256, 256, 3, 1, 1)\n",
    "        self.conv8 = nn.Conv2d(256, 512, 3, 1, 1)\n",
    "        self.conv9 = nn.Conv2d(512, 512, 3, 1, 1)\n",
    "        self.conv10 = nn.Conv2d(512, 512, 3, 1, 1)\n",
    "        self.conv11 = nn.Conv2d(512, 512, 3, 1, 1)\n",
    "        self.conv12 = nn.Conv2d(512, 512, 3, 1, 1)\n",
    "        self.conv13 = nn.Conv2d(512, 512, 3, 1, 1)\n",
    "        self.fc1 = nn.Linear(25088, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, num_classes)\n",
    "        \n",
    "        # intializing weights\n",
    "        self.initialize_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.relu(self.conv5(x))\n",
    "        x = self.relu(self.conv6(x))\n",
    "        x = self.relu(self.conv7(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.relu(self.conv8(x))\n",
    "        x = self.relu(self.conv9(x))\n",
    "        x = self.relu(self.conv10(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.relu(self.conv11(x))\n",
    "        x = self.relu(self.conv12(x))\n",
    "        x = self.relu(self.conv13(x))\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.dropout(self.fc1(x)))\n",
    "        x = self.relu(self.dropout(self.fc2(x)))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d):\n",
    "                torch.nn.init.kaiming_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    torch.nn.init.constant_(m.bias, 0)\n",
    "                        \n",
    "            elif isinstance(m, torch.nn.BatchNorm2d):\n",
    "                torch.nn.init.constant_(m.weight, 1)\n",
    "                torch.nn.init.constant_(m.bias, 1)\n",
    "                    \n",
    "            elif isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.kaiming_uniform_(m.weight)\n",
    "                torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "device = get_default_device()\n",
    "print(device)\n",
    "\n",
    "\n",
    "NUM_CLASSES = 10 #102\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32 #128\n",
    "\n",
    "model = vggnet16(NUM_CLASSES).to(device)\n",
    "\n",
    "# testing\n",
    "input = torch.rand([BATCH_SIZE,3,IMG_SIZE,IMG_SIZE]).to(device)\n",
    "out = model(input)\n",
    "print(\"input shape:\", input.shape)\n",
    "print(\"output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function <lambda> at 0x000001F265CF95E0>: attribute lookup <lambda> on __main__ failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m data_transforms \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((IMG_SIZE, IMG_SIZE)),\n\u001b[0;32m      3\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mRandomHorizontalFlip(),\n\u001b[0;32m      4\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(), \u001b[38;5;66;03m# Scales data into [0,1]\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m t: (t \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Scale between [-1, 1]\u001b[39;00m\n\u001b[0;32m      6\u001b[0m ]\n\u001b[0;32m      8\u001b[0m trainloader, testloader \u001b[38;5;241m=\u001b[39m get_dataset(dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcifar10\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mdata_transforms, batchsize \u001b[38;5;241m=\u001b[39m BATCH_SIZE)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m device \u001b[38;5;241m=\u001b[39m get_default_device()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#device = torch.device('cpu')\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\percy\\dl\\cnns\\utils.py:59\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(loader)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimshow\u001b[39m(loader):\n\u001b[1;32m---> 59\u001b[0m     dataiter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39;49m(loader)\n\u001b[0;32m     60\u001b[0m     images, labels \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(dataiter)\n\u001b[0;32m     61\u001b[0m     img \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mmake_grid(images)\n",
      "File \u001b[1;32mc:\\Users\\percy\\anaconda3\\envs\\vision\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:444\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    443\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32mc:\\Users\\percy\\anaconda3\\envs\\vision\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:390\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    389\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 390\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\percy\\anaconda3\\envs\\vision\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1077\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1070\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1074\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1075\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1077\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1078\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1079\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\percy\\anaconda3\\envs\\vision\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\percy\\anaconda3\\envs\\vision\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\percy\\anaconda3\\envs\\vision\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\percy\\anaconda3\\envs\\vision\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\percy\\anaconda3\\envs\\vision\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m     \u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x000001F265CF95E0>: attribute lookup <lambda> on __main__ failed"
     ]
    }
   ],
   "source": [
    "data_transforms = [\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), # Scales data into [0,1]\n",
    "    transforms.Lambda(lambda t: (t * 2) - 1) # Scale between [-1, 1]\n",
    "]\n",
    "\n",
    "trainloader, testloader = get_dataset(dataset_name='cifar10', transform=data_transforms, batchsize = BATCH_SIZE)\n",
    "imshow(testloader)\n",
    "\n",
    "device = get_default_device()\n",
    "#device = torch.device('cpu')\n",
    "trained_model = train(net=model,\n",
    "                    epochs=1,\n",
    "                    trainloader = trainloader,\n",
    "                    criterion = nn.CrossEntropyLoss(),\n",
    "                    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
    "                    device = device,\n",
    "                    every_n_epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './trained_models/vggnet'\n",
    "create_directory(PATH)\n",
    "save_model(PATH, model=trained_model, weights='vggnet16.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('vision')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "214ee178f1715f47f83f7b184c1addbfc9e625d5c3d67f84a9eb2959c677c7e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
